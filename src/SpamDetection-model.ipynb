{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Detection\n",
    "https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
    "\n",
    "### Downloaded here:\n",
    "\n",
    "data/YouTube-Spam-Collection-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_words(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'<[^>]+>', ' ', sent) #strip html tags\n",
    "    sent = re.sub(r'(\\w)\\'(\\w)', '\\1\\2', sent) # remoce apostrophes\n",
    "    sent = re.sub(r'\\W',' ', sent) # remove punctuation\n",
    "    sent = re.sub(r'\\s+', ' ', sent) # remove repeated space\n",
    "    sent = sent.strip()\n",
    "    return sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ajshd', 'asda', '1231', 'sd', 'alkdj']\n"
     ]
    }
   ],
   "source": [
    "# test text cleanup block\n",
    "words = 'ajshd asda, + 1231 \"sd + ''alkdj''    '\n",
    "print(extract_words(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load doc to vec model\n",
    "doc2vec_model_name = 'reviews.d2v'\n",
    "model = Doc2Vec.load(doc2vec_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00062089,  0.2351284 , -0.03454486, -0.05228289, -0.02684396,\n",
       "       -0.09259088, -0.02277846, -0.12211672,  0.16191505,  0.01832944,\n",
       "       -0.11064825, -0.24176133, -0.20306163, -0.04831441,  0.07895452,\n",
       "        0.09381681,  0.11844175,  0.13362783,  0.10960958,  0.22026704,\n",
       "       -0.33733156,  0.03500133,  0.03830094, -0.09355066,  0.0709269 ,\n",
       "        0.15171033,  0.08753077,  0.15251824,  0.06004937,  0.07809102,\n",
       "        0.31834617, -0.05555944,  0.14290863, -0.14791834, -0.09593711,\n",
       "        0.15710084,  0.13722666, -0.07485071,  0.39205426, -0.15195712,\n",
       "       -0.23429897, -0.27143204, -0.23950902, -0.10757922,  0.21703528,\n",
       "       -0.03553951,  0.07372943, -0.03376171, -0.08742584,  0.15654385],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(extract_words(\"This is very bad video. I don't like it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7280318]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "[model.infer_vector(extract_words(\"This is very bad video. I don't like it\"))],\n",
    "[model.infer_vector(extract_words(\"video sucks.\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43282947]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "[model.infer_vector(extract_words(\"It is now snowing in New York\"))],\n",
    "[model.infer_vector(extract_words(\"I feel sick. Dont feel like going to school\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([pd.read_csv(\"data/YouTube-Spam-Collection-v1/Youtube01-Psy.csv\"), \n",
    "               pd.read_csv(\"data/YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv\"),\n",
    "              pd.read_csv(\"data/YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv\"),\n",
    "              pd.read_csv(\"data/YouTube-Spam-Collection-v1/Youtube04-Eminem.csv\"),\n",
    "              pd.read_csv(\"data/YouTube-Spam-Collection-v1/Youtube05-Shakira.csv\")])\n",
    "d = d.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416                    every bady yust have a good time﻿\n",
       "42     they Shuffle hard that they made an Earthquake...\n",
       "284    The Perry you're doing a good job good job I l...\n",
       "253    I am now going to voyage to the first comment....\n",
       "118                  Very pleasant to hear, haha, good.﻿\n",
       "Name: CONTENT, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['CONTENT'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['WORDS'] = d['CONTENT'].map(lambda x: extract_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416             [every, bady, yust, have, a, good, time]\n",
       "42     [they, shuffle, hard, that, they, made, an, ea...\n",
       "284    [the, perry, yo, e, doing, a, good, job, good,...\n",
       "253    [i, am, now, going, to, voyage, to, the, first...\n",
       "118               [very, pleasant, to, hear, haha, good]\n",
       "Name: WORDS, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['WORDS'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = d['CONTENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['SENTVECS'] = d['WORDS'].map(lambda x: model.infer_vector(x, steps=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416    [-0.07048194, 0.30158433, 0.055230945, -0.1037...\n",
       "42     [0.018265551, 0.14901805, 0.06305703, 0.103425...\n",
       "284    [0.21629643, 0.37278166, 0.47778076, 0.1357919...\n",
       "253    [0.036792, -0.076096356, 0.32669353, -0.204220...\n",
       "118    [0.12418369, 0.37762502, 0.14810343, -0.269280...\n",
       "Name: SENTVECS, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['SENTVECS'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentvecs = d['SENTVECS'].tolist()\n",
    "labels = d['CLASS'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfkn = KNeighborsClassifier(n_neighbors=9)\n",
    "clfrf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg : 0.9059188892948484 std : 0.012107819061874497\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clfkn, sentvecs, labels, cv =5)\n",
    "print(\"avg : {0} std : {1}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg : 0.8992757972754319 std : 0.013055168550590612\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clfrf, sentvecs, labels, cv =5)\n",
    "print(\"avg : {0} std : {1}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model and save it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "clfkn.fit(sentvecs, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "clfrf.fit(sentvecs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred : [0 0 1 1 0 1 1 0 1 1]\n",
      "y_test : [0, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfkn.predict(sentvecs[0:10])\n",
    "print(\"y_pred : {0}\".format(y_pred))\n",
    "y_test = labels[0:10]\n",
    "print(\"y_test : {0}\".format(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy : {0}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metrics : \n",
      "[[4 1]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "cf = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Metrics : \\n{0}\".format(cf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc2vec_spam_kn.model']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'doc2vec_spam_kn.model'\n",
    "joblib.dump(clfkn, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc2vec_spam_rf.model']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'doc2vec_spam_rf.model'\n",
    "joblib.dump(clfrf, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "model_name = 'doc2vec_spam_rf.sav'\n",
    "pickle.dump(clfrf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "result = loaded_model.score(sentvecs[0:10], labels[0:10])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-Words model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg : 0.937115715851558 std : 0.012280288547147656\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline, sentences, labels, cv =5)\n",
    "print(\"avg : {0} std : {1}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag-of-Words and Doc2Vec performance seems to be close. However, if we have lot more training example Doc2Vec works better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
