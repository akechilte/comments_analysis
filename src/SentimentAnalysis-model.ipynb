{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_words(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'<[^>]+>', ' ', sent) #strip html tags\n",
    "    sent = re.sub(r'(\\w)\\'(\\w)', '\\1\\2', sent) # remoce apostrophes\n",
    "    sent = re.sub(r'\\W',' ', sent) # remove punctuation\n",
    "    sent = re.sub(r'\\s+', ' ', sent) # remove repeated space\n",
    "    sent = sent.strip()\n",
    "    return sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'bad', 'ugly']\n"
     ]
    }
   ],
   "source": [
    "# test text cleanup block\n",
    "words = 'Good, + bad / \"ugly + '';''    '\n",
    "print(extract_words(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_root = os.path.dirname(os.getcwd())\n",
    "#print(\"Current working dir : {0}\".format(proj_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = proj_root + \"/\" + \"model\"\n",
    "doc2vec_model = model_dir + \"/\" + 'comments.d2v'\n",
    "\n",
    "#Load doc to vec model\n",
    "model = Doc2Vec.load(doc2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0007488 ,  0.23022519, -0.02249053, -0.05488956, -0.03843215,\n",
       "       -0.09444682, -0.02938818, -0.12492562,  0.15748744,  0.01971101,\n",
       "       -0.12412424, -0.24856669, -0.20035094, -0.03914883,  0.09236484,\n",
       "        0.09049756,  0.12286548,  0.12651494,  0.11997791,  0.22038384,\n",
       "       -0.34141788,  0.04001606,  0.03116315, -0.08485164,  0.08007647,\n",
       "        0.15309156,  0.07524484,  0.15937917,  0.06037891,  0.07296979,\n",
       "        0.31113595, -0.05051051,  0.13974777, -0.15265502, -0.10611851,\n",
       "        0.15341866,  0.14397682, -0.07252364,  0.38951796, -0.14550473,\n",
       "       -0.24489135, -0.27200776, -0.23849759, -0.10863675,  0.21872744,\n",
       "       -0.04544033,  0.08326463, -0.02799641, -0.08214579,  0.16252297],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(extract_words(\"This is very bad video. I don't like it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name : amazon.txt\n",
      "file name : imdb.txt\n",
      "file name : yelp.txt\n"
     ]
    }
   ],
   "source": [
    "labeled_senti_subdir = 'traindata/labeled-senti-data'\n",
    "labeled_senti_dir = proj_root + \"/\" + labeled_senti_subdir\n",
    "\n",
    "sentences = []\n",
    "sentvecs = []\n",
    "sentiments = []\n",
    "\n",
    "\n",
    "for fname in sorted(os.listdir(labeled_senti_dir)):\n",
    "    print(\"file name : {0}\".format(fname))\n",
    "    if fname.endswith('.txt'):\n",
    "        with open(labeled_senti_dir + \"/\" + fname, encoding = 'UTF-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line_split = line.strip().split('\\t')\n",
    "                sentences.append(line_split[0])\n",
    "                words = extract_words(line_split[0])\n",
    "                sentvecs.append(model.infer_vector(words, steps=10))\n",
    "                sentiments.append(int(line_split[1]))\n",
    "        \n",
    "combined = list(zip(sentences, sentvecs, sentiments))\n",
    "random.shuffle(combined)\n",
    "sentences, sentvecs, sentiments = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I didn't think that the instructions provided were helpful to me.\",\n",
       " \"I promise they won't disappoint.\")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.48536435, -0.17653368,  0.2098451 , -0.20381974,  0.09497128,\n",
       "        -0.044964  ,  0.3941045 , -0.5218856 , -0.1571676 ,  0.16231482,\n",
       "         0.05511091, -0.17999406,  0.07783119,  0.03506007,  0.41333073,\n",
       "        -0.15531571, -0.14621882, -0.1358074 , -0.02331984,  0.01832723,\n",
       "        -0.05436605, -0.04734341,  0.08598659, -0.2657693 , -0.22395723,\n",
       "         0.03232431, -0.10989751,  0.5301082 , -0.2534588 ,  0.24355558,\n",
       "         0.43762696,  0.09672873,  0.24846926,  0.18541782,  0.03174235,\n",
       "        -0.09439711,  0.2080433 , -0.28092685,  0.3195152 , -0.0998478 ,\n",
       "        -0.3149838 , -0.01844147,  0.21288288, -0.21128532,  0.1586669 ,\n",
       "        -0.05897464,  0.20594312, -0.24821277, -0.6573384 ,  0.07050503],\n",
       "       dtype=float32),\n",
       " array([-0.14356126,  0.19225422, -0.01631394,  0.13989933,  0.05279529,\n",
       "        -0.10171934,  0.1476186 , -0.31477496,  0.23688883,  0.07492894,\n",
       "         0.05177709,  0.13395412, -0.0982677 , -0.0616399 ,  0.09610128,\n",
       "        -0.05369568, -0.14166313, -0.09904359,  0.05080348,  0.07556948,\n",
       "        -0.04249036, -0.15615962, -0.10156694, -0.15122537,  0.19519651,\n",
       "        -0.01553052, -0.02022927,  0.15754955, -0.05877652,  0.00154736,\n",
       "         0.13991995,  0.0790871 ,  0.319149  ,  0.23985714, -0.16126037,\n",
       "         0.32827866,  0.34897232, -0.12966464,  0.20901212, -0.07200775,\n",
       "        -0.06916575, -0.45708287, -0.09617259, -0.04924145,  0.23467255,\n",
       "        -0.07010815,  0.47574723,  0.18255727, -0.0998068 ,  0.1809329 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentvecs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfkn = KNeighborsClassifier(n_neighbors=9)\n",
    "clfrf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg : 0.7853333333333333 std : 0.004268749491621889\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clfkn, sentvecs, sentiments, cv =5)\n",
    "print(\"avg : {0} std : {1}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg : 0.7386666666666667 std : 0.01180395413975053\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clfrf, sentvecs, sentiments, cv =5)\n",
    "print(\"avg : {0} std : {1}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model and save it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "clfkn.fit(sentvecs, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "clfrf.fit(sentvecs, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred : [0 1 0 1 0 1 0 0 1 1]\n",
      "y_test : (0, 1, 0, 0, 0, 1, 0, 0, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfkn.predict(sentvecs[0:10])\n",
    "print(\"y_pred : {0}\".format(y_pred))\n",
    "y_test = sentiments[0:10]\n",
    "print(\"y_test : {0}\".format(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy : {0}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metrics : \n",
      "[[5 1]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "cf = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Metrics : \\n{0}\".format(cf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = proj_root + \"/\" + \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/dbiswas/Documents/Malabika/MS/Fall2018/social_media_mining/project/comments_analysis/model/doc2vec_senti_kn.model']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Persist the model to disk\n",
    "model_name = model_dir + \"/\" + 'doc2vec_senti_kn.model'\n",
    "joblib.dump(clfkn, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/dbiswas/Documents/Malabika/MS/Fall2018/social_media_mining/project/comments_analysis/model/doc2vec_senti_rf.model']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Persist the model to disk\n",
    "model_name = model_dir + \"/\" + 'doc2vec_senti_rf.model'\n",
    "joblib.dump(clfrf, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Demo with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "model_name = model_dir + \"/\" + 'doc2vec_senti_rf.pickle'\n",
    "pickle.dump(clfrf, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-Words model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg : 0.748 std : 0.01941934888483933\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline, sentences, sentiments, cv =5)\n",
    "print(\"avg : {0} std : {1}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag-of-Words and Doc2Vec performance seems to be close. However, if we have lot more training example Doc2Vec works better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
